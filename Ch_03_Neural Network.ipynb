{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch03 신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "퍼셉트론은 가중치와 편향을 일일이 조정해야 하는 불편함이 있다.\n",
    "\n",
    "하지만 신경망은 그런 일을 스스로 함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 퍼셉트론에서 신경망으로\n",
    "\n",
    "3.1.1 신경망의 예\n",
    "\n",
    "그림 3-1 :신경망은 입력층, 은닉층, 출력층으로 구성\n",
    "\n",
    "3.1.2 퍼셉트론 복습\n",
    "\n",
    "식 3.1 : 퍼셉트론은 편향과 가중치를 통해 설명됨.\n",
    "\n",
    "그림 3.3 : 퍼셉트론의 편향을 가시화.\n",
    "\n",
    "식 3.1을 좀 더 간결히 식 3.2와 식 3.3으로 표현 가능.\n",
    "\n",
    "3.1.3 활성화 함수\n",
    "\n",
    "앞서 정의한 $h$를 활성화 함수라고 한다.\n",
    "\n",
    "그림 3.4 : 활성화 함수 처리 과정\n",
    "\n",
    "그림 3.5 : 일반적인 뉴런과 활성화 과정을 강조한 뉴런"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 활성화 함수\n",
    "\n",
    "식 3.3 은 step function이다. \n",
    "그러면 꼭 활성화 함수를 step function으로만 사용해야하나?\n",
    "다른 함수도 사용이 가능.\n",
    "\n",
    "3.2.1 시그모이드 함수\n",
    "\n",
    "식 3.6 : 시그모이드 함수 정의\n",
    "\n",
    "3.2.2 step function 구현\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Step function\n",
    "def step_function(x):\n",
    "    if x>0:\n",
    "        return 1\n",
    "    else :\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_function(2),step_function(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 step function은 정의역이 실수밖에 안된다.\n",
    "\n",
    "$\\mathbb{R}^{n}$ 같은 벡터를 인자로 가지려면,,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def step_function(x):\n",
    "    y = x > 0\n",
    "    return y.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_function(np.array([2,-1])) #각각 원소마다 step function이 적용 되는듯."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1,  2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#위의 코드 풀어보자.\n",
    "x = np.array([-1, 1, 2])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True], dtype=bool)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x > 0 #넘피 배열에 부등호 연산을 취하면 원소 각각에 부등호로 bool 연산 수행\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.astype(np.int) #True, False 타입을 int형 변수로 바꿔줌.\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.3 step function 그래프\n",
    "\n",
    "그래프 그리기 위해 matplotlib 라이브러리 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgUAAAFdCAYAAACTqR4KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xe85e6e7278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pylab as plt\n",
    "\n",
    "def step_function(x):\n",
    "    return np.array(x>0, dtype=np.int)\n",
    "    \n",
    "x = np.arange(-5, 5, 0.1) #-5에서 5까지 0.1 간격의 배열 생성\n",
    "y = step_function(x)\n",
    "\n",
    "plt.plot(x,y) #(x,y) 점찍을듯.\n",
    "plt.ylim(-0.1,1.1) #y축 범위 지정\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.4 시그모이드 함수 구현\n",
    "\n",
    "Similarly 시그모이드 함수도 해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x가 실수이든 배열이든 상관없이 값을 반환함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2689414213699951"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.26894142,  0.73105858,  0.88079708])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(np.array([-1,1,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시그모이드 함수 그래프 그려보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgUAAAFdCAYAAACTqR4KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndBMlie/sTQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xe85edac240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(-5, 5, 0.1)\n",
    "y = sigmoid(x)\n",
    "plt.plot(x,y)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.5 시그모이드 함수와 step function 비교\n",
    "\n",
    "시그모이드 -> 미분 가능\n",
    "\n",
    "step function -> 미분 불능\n",
    "\n",
    "3.2.6 비선형 함수\n",
    "\n",
    "시그모이드, step function 둘다 비선형 함수인데, 신경망에서 사용되는 활성함수는 주로 비선형 함수를 사용한다.\n",
    "\n",
    "활성함수로 선형함수를 사용하게 되면 층을 여러개하는 의미가 사라짐.\n",
    "(여러개로 해도 곧 하나의 선형함수로 표현이 가능함)\n",
    "\n",
    "3.2.7 ReLu 함수\n",
    "\n",
    "Rectified Linear Unit(렐루) 함수, 최근에 많이 사용됨.\n",
    "\n",
    "식 3.7 처럼 나타나고 그래프는 그림 3.9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Re Lu 함수 구현\n",
    "def relu(x):\n",
    "    return np.maximum(0,x) #우리가 아는 그 max다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAFkCAYAAAC9wjgoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAF1ZJREFUeJzt3X2QZWldH/Dvj5XIyyZD6caNGxaQIuIaBOwGFVNAKQQS\nLSHGYqSFRQaBWaLZrUkslSQUSiWKGl4K3V0TWVhhhk5IlSRYiWLhBlJgYEM3rJViRrO8I7jylpba\nWQwvT/64PWvP7Lz07elzzzn3fD5VU8Xc6Xufh1Oz3d85v+99brXWAgBM17363gAA0C9hAAAmThgA\ngIkTBgBg4oQBAJg4YQAAJk4YAICJEwYAYOKEAQCYOGEAACau0zBQVS+tqq+d8euDXa4JAMzn6xaw\nxv9O8qQktf37ryxgTQBglxYRBr7SWvvMAtYBAPZgEZ2Bv1NVf1pVH6qqo1V15QLWBAB2qbr8COOq\nemqSS5P8cZJvTvLzSa5I8ojW2p1n+fpvTPLUJB9N8qXONgYAy+c+SR6S5G2ttc/N88ROw8A9Fqs6\nkORjSY601l5/lj//sSTHFrYhAFg+z2qtvWmeJyyiM3C31tpWVf1Jkoed40s+miRHjx7NVVddtbB9\nLYMjR47kVa96Vd/bGBXXbG9ct/m5Znvjus3n+PHjefazn51s/yydx0LDQFVdmlkQeMM5vuRLSXLV\nVVdlZWVlYftaBgcOHHDN5uSa7Y3rNj/XbG9ctz2be8ze9TkDv1pVT6iqB1fV9yZ5S5IvJ1nvcl0A\nYPe6vjPwwCRvSvKNST6T5F1JvmfeYgMA0J1Ow0Brba3L1wcALp7PJlgSa2ty17xcs71x3ebnmu2N\n67Y4C31r4YVU1UqSjY2NDaURAJjD5uZmVldXk2S1tbY5z3PdGQCAiRMGAGCHO+9xPu7yEwYAYNuJ\nE8m3fEvyznf2vZPFEgYAIMnJk8kznpFcdlnymMf0vZvFWugJhAAwVNddl3zoQ8mttyb3v3/fu1ks\nYQCAyTt6NHnta5PXvS55xCP63s3iGRMAMGknTiTXXJM85znJc5/b9276IQwAMFmnegIPelByww1J\nVd876ocxAQCTNeWewE7CAACTNPWewE7GBABMjp7A6YQBACZFT+CejAkAmBQ9gXsSBgCYDD2BszMm\nAGAS9ATOTRgAYOnpCZyfMQEAS09P4PyEAQCWmp7AhRkTALC09AR2RxgAYCnpCeyeMQEAS0lPYPeE\nAQCWjp7AfIwJAFgqegLzEwYAWBp6AntjTADA0tAT2BthAICloCewd8YEAIyensDFEQYAGDU9gYtn\nTADAqOkJXDxhAIDR0hPYH8YEAIySnsD+EQYAGB09gf1lTADA6OgJ7C9hAIBR0RPYf8YEAIzGqZ7A\n1VfrCewnYQCAUdjZE7jxRj2B/WRMAMAo6Al0RxgAYPD0BLplTADAoDlPoHsLCwNV9XNV9bWqeuWi\n1gRg3JwnsBgLGRNU1WOTvDDJbYtYD4DloCewGJ3fGaiqS5McTfL8JP+36/UAWA6negLXX68n0LVF\njAmuT/I7rbVbFrAWAEtAT2CxOh0TVNUzkzw6yWO6XAeA5XHXXcnBg3oCi9RZGKiqByZ5dZInt9a+\nPM9zjxw5kgMHDpz22NraWtbW1vZxhwAM0bXXJrffridwPuvr61lfXz/tsa2trT2/XrXWLnZPZ3/h\nqqcn+e0kX01yKtddkqRtP/b17YzFq2olycbGxkZWVlY62RcAw3X06Oyo4de9Ljl0qO/djMvm5mZW\nV1eTZLW1tjnPc7scE7w9yXec8djNSY4nefmZQQCAadMT6E9nYaC1dmeSD+58rKruTPK51trxrtYF\nYHycJ9CvRR9H7G4AAPfgPIF+LTQMtNa+f5HrATB8Pnegfz6bAIDe6AkMgzAAQC/0BIbDRxgD0As9\ngeEQBgBYOD2BYTEmAGCh9ASGRxgAYGH0BIbJmACAhdETGCZhAICF0BMYLmMCADqnJzBswgAAndIT\nGD5jAgA6pScwfMIAAJ3RExgHYwIAOqEnMB7CAAD7Tk9gXIwJANh3egLjIgwAsK9O9QRuuklPYCyM\nCQDYNzt7AocO9b0bdksYAGBf6AmMlzEBAPtCT2C8hAEALprzBMbNmACAi+I8gfETBgDYMz2B5WBM\nAMCe6QksB2EAgD3RE1gexgQAzE1PYLkIAwDM5VRP4Mor9QSWhTEBAHPRE1g+wgAAu6YnsJyMCQDY\nFT2B5SUMAHBBzhNYbsYEAFyQnsByEwYAOC89geVnTADAOekJTIMwAMBZ6QlMhzEBAGelJzAdwgAA\n93DsmJ7AlBgTAHCaEyeSw4f1BKZEGADgbnoC02RMAMDd9ASmSRgAIInzBKas0zFBVV1TVbdV1db2\nrz+sqn/Q5ZoAzM95AtPWdWfgE0l+NslKktUktyT5L1V1VcfrArBLegJ0OiZorf3XMx76V1X1oiTf\nk+R4l2sDsDt6AiysM1BV90pyMMn9kvzPRa0LwLnpCZAsIAxU1SMy++F/nyRfTPLDrbUTXa8LwPnp\nCXDKIs4ZOJHkUUm+K8mNSd5QVd+2gHUBOIeTJ5ODB/UEmOn8zkBr7StJPrz92/dX1XcluS7Ji871\nnCNHjuTAgQOnPba2tpa1tbXO9gkwJdddl9x+u57AWK2vr2d9ff20x7a2tvb8etVau9g9zbdg1R8k\n+Vhr7Xln+bOVJBsbGxtZWVlZ6L4ApuLo0eTqq2c9gUOH+t4N+2VzczOrq6tJstpa25znuZ3eGaiq\nX0zyu0k+nuSvJ3lWkicmeUqX6wJwdnoCnE3XY4JvSvJbSb45yVaSP0rylNbaLR2vC8AZnCfAuXR9\nzsDzu3x9AHbPeQKci88mAJgA5wlwPj7CGGDJ6QlwIcIAwBLTE2A3jAkAlpieALshDAAsqWPH9ATY\nHWMCgCV04kRy+PDscCE9AS5EGABYMjt7AjfeqCfAhRkTACwZPQHmJQwALBHnCbAXxgQAS8J5AuyV\nMACwBJwnwMUwJgBYAnoCXAxhAGDk9AS4WMYEACOmJ8B+EAYARkpPgP1iTAAwUnoC7BdhAGCE9ATY\nT8YEACOjJ8B+EwYARkRPgC4YEwCMiJ4AXRAGAEZCT4CuGBMAjICeAF0SBgAGTk+ArhkTAAycngBd\nEwYABkxPgEUwJgAYKD0BFkUYABigUz2BK69Mrr9eT4BuGRMADNDOnsCll/a9G5adMAAwMHoCLJox\nAcCA6AnQB2EAYCCcJ0BfjAkABsJ5AvRFGAAYAD0B+mRMANAzPQH6JgwA9EhPgCEwJgDokZ4AQyAM\nAPTkVE/gppv0BOiXMQFAD3b2BA4d6ns3TJ0wALBgegIMjTEBwILpCTA0wgDAAjlPgCHqdExQVS+u\nqlur6i+q6o6qektVfWuXawIMlfMEGKquOwOPT/JrSb47yZOT3DvJ71fVfTteF2BQ9AQYsk7HBK21\nH9j5+6p6bpI/T7Ka5F1drg0wJHoCDNmiOwMPSNKSfH7B6wL0Rk+AoVvYWwurqpK8Osm7WmsfXNS6\nAH3SE2AMFnln4IYk357k713oC48cOZIDBw6c9tja2lrW1tY62hrA/jt5Mjl4UE+A/be+vp719fXT\nHtva2trz61Vr7WL3dOFFqn49yQ8leXxr7ePn+bqVJBsbGxtZWVnpfF8AXXrBC5Jjx2Y9AeMBura5\nuZnV1dUkWW2tbc7z3M7vDGwHgacneeL5ggDAMtETYEw6DQNVdUOStSRPS3JnVV2+/UdbrbUvdbk2\nQF/0BBibrguE1yT5G0nekeRTO34d7HhdgF44T4Ax6vqcAR+EBEyK8wQYI59NALBP9AQYK/9yB9gH\negKMmTAAcJH0BBg7YwKAi6QnwNgJAwAXQU+AZWBMALBHp3oCV1+tJ8C4CQMAe7CzJ3DjjXoCjJsx\nAcAe6AmwTIQBgDnpCbBsjAkA5uA8AZaRMACwS84TYFkZEwDskp4Ay0oYANgFPQGWmTEBwAXoCbDs\nhAGA87jrruTgQT0BlpsxAcB5XHttcvvtegIsN2EA4Bz0BJgKYwKAs9ATYEqEAYAzOE+AqTEmADiD\n8wSYGmEAYAc9AabImABgm54AUyUMAERPgGkzJgCIngDTJgwAk6cnwNQZEwCTpicAwgAwYXoCMGNM\nAEyWngDMCAPAJOkJwF8xJgAmR08ATicMAJOiJwD3ZEwATIqeANyTMABMhp4AnJ0xATAJegJwbsIA\nsPT0BOD8jAmApacnAOcnDABL7VRP4Kab9ATgXIwJgKW1sydw6FDfu4HhEgaApaQnALtnTAAsJT0B\n2D1hAFg6zhOA+XQ6Jqiqx1fVW6vqT6vqa1X1tC7XA3CeAMyv687A/ZN8IMk/SdI6XguYOD0B2JtO\nxwSttd9L8ntJUuU/S6BbegKwNzoDwFLQE4C989ZCYPT0BODiDPLOwJEjR3LgwIHTHltbW8va2lpP\nOwKG6lRP4Mor9QSYjvX19ayvr5/22NbW1p5fr1pbTK+vqr6W5B+11t56nq9ZSbKxsbGRlZWVhewL\nGLcXvCA5dmzWEzAeYMo2NzezurqaJKuttc15njvIOwMAu6EnAPuj0zBQVfdP8rAkp27cPbSqHpXk\n8621T3S5NrDc9ARg/3R9Z+AxSf57ZmcMtCSv2H78t5I8r+O1gSXlPAHYX12fM/DOeMcCsM+cJwD7\nS2cAGBU9Adh//tUOjIaeAHRDGABGQU8AumNMAIyCngB0RxgABu/YMT0B6JIxATBoJ04khw/rCUCX\nhAFgsPQEYDGMCYDB0hOAxRAGgEFyngAsjjEBMDjOE4DFEgaAQdETgMUzJgAGRU8AFk8YAAZDTwD6\nYUwADIKeAPRHGAB6d/JkcvCgngD0xZgA6N111yW3364nAH0RBoBe6QlA/4wJgN7oCcAwCANAL5wn\nAMNhTAD0wnkCMBzCALBwegIwLMYEwELpCcDwCAPAwugJwDAZEwALoycAwyQMAAtx7JieAAyVMQHQ\nuRMnksOHk6uv1hOAIRIGgE7t7AnceKOeAAyRMQHQKT0BGD5hAOiM8wRgHIwJgE44TwDGQxgA9p3z\nBGBcjAmAfacnAOMiDAD7Sk8AxseYANg3egIwTsIAsC/0BGC8jAmAfaEnAOMlDAAXTU8Axs2YALgo\negIwfsIAsGd6ArAcjAmAPdMTgOXQ+Z2BqvrJqvpIVd1VVe+pqsd2vSbQvVM9geuv1xOAses0DFTV\njyZ5RZKXJvnOJLcleVtVXdblukC3jh9PDh/WE4Bl0fWdgSNJ/l1r7Q2ttRNJrklyMsnzOl4X6MjJ\nk8nBg8mDH6wnAMuis85AVd07yWqSXzz1WGutVdXbkzyuq3WBbl17rZ4ALJsuC4SXJbkkyR1nPH5H\nkod3uC7QkTe+MbnpJucJwLLxboJdeuQjk09/uu9dQL++8AU9AVhGXYaBzyb5apLLz3j88iR/dr4n\nHjlyJAcOHDjtsbW1taytre3rBufxwhcmX/xib8vDIFx6afITP6EnAH1bX1/P+vr6aY9tbW3t+fWq\ntXaxezr3i1e9J8l7W2vXbf++knw8yWtaa796lq9fSbKxsbGRlZWVzvYFAMtmc3Mzq6urSbLaWtuc\n57ldjwlemeTmqtpIcmtm7y64X5KbO14XANilTsNAa+3N22cKvCyz8cAHkjy1tfaZLtcFAHav8wJh\na+2GJDd0vQ4AsDc+qAgAJk4YAICJEwYAYOKEAQCYOGEAACZOGACAiRMGAGDihAEAmDhhAAAmThgA\ngIkTBgBg4oQBAJg4YQAAJk4YAICJEwYAYOKEAQCYOGEAACZOGACAiRMGAGDihAEAmDhhAAAmThgA\ngIkTBgBg4oQBAJg4YQAAJk4YAICJEwYAYOKEAQCYOGEAACZOGACAiRMGAGDihAEAmDhhAAAmThgA\ngIkTBgBg4oQBAJg4YQAAJk4YAICJEwYAYOKEAQCYOGFgSayvr/e9hdFxzfbGdZufa7Y3rtvidBYG\nqupfVNW7q+rOqvp8V+sw4z+a+blme+O6zc812xvXbXG6vDNw7yRvTnJjh2sAABfp67p64dbaLyRJ\nVf14V2sAABdPZwAAJq6zOwN7dJ8kOX78eN/7GJ2tra1sbm72vY1Rcc32xnWbn2u2N67bfHb87LzP\nvM+t1truv7jql5L87Hm+pCW5qrX2Jzue8+NJXtVa+4ZdvP6PJTm26w0BAGd6VmvtTfM8Yd47A/82\nyesv8DUfnvM1d3pbkmcl+WiSL13E6wDA1NwnyUMy+1k6l7nCQGvtc0k+N+8ic77+XGkGALjbH+7l\nSZ11BqrqyiTfkOTBSS6pqkdt/9HtrbU7u1oXAJjPXJ2BuV646vVJnnOWP/q+1tr/6GRRAGBunYUB\nAGAcnDMAABMnDADAxA06DFTVD1bVe6rqZFV9vqp+u+89jUVV/bWq+kBVfa2qHtn3foaqqh5cVa+t\nqg9v/z37P1X181V17773NjRV9ZNV9ZGqumv7v8vH9r2nIauqF1fVrVX1F1V1R1W9paq+te99jUlV\n/dz297BX9r2XoauqK6rqjVX12e3vZbdV1cpunz/YMFBVP5LkDUluSvIdSb433nY4j19J8snMDoLi\n3L4tSSV5QZJvT3IkyTVJ/k2fmxqaqvrRJK9I8tIk35nktiRvq6rLet3YsD0+ya8l+e4kT87sw9t+\nv6ru2+uuRmI7bL4ws79rnEdVPSDJu5P8ZZKnJrkqyT9P8oVdv8YQC4RVdUlmBw+9pLV2c7+7GZ+q\n+oeZHRD1I0k+mOTRrbU/6ndX41FVP53kmtbaw/rey1BU1XuSvLe1dt327yvJJ5K8prX2K71ubiS2\ng9OfJ3lCa+1dfe9nyKrq0iQbSV6U5CVJ3t9a+2f97mq4qurlSR7XWnviXl9jqHcGVpJckSRVtVlV\nn6qq/1ZVf7fnfQ1eVV2e5N8neXaSu3rezlg9IMnn+97EUGyPTFaT/MGpx9rsXxFvT/K4vvY1Qg/I\n7E6dv1sXdn2S32mt3dL3Rkbih5K8r6revD2S2qyq58/zAkMNAw/N7NbtS5O8LMkPZna74x3bt0M4\nt9cnuaG19v6+NzJGVfWwJD+V5Df63suAXJbkkiR3nPH4HUn+1uK3Mz7bd1JeneRdrbUP9r2fIauq\nZyZ5dJIX972XEXloZndR/jjJU5LcmOQ1VXX1bl9goWGgqn5puwxyrl9f3S7YnNrXv26t/eftH2yH\nMkvVz1jknodgt9etqq5NcmmSXz711B633as5/q7tfM7fTvK7Sf5ja+11/eycJXVDZp2UZ/a9kSGr\nqgdmFpqe1Vr7ct/7GZF7Jdlorb2ktXZba+03k/xmZv2nXVn0Rxjv9oOOrtj+33d/HmNr7f9V1YeT\nPKijvQ3Zbq7bR5J8X2a3bf9y9g+Ru72vqo611g51tL8hmutDtarqiiS3ZPYvt8NdbmyEPpvkq0ku\nP+Pxy5P82eK3My5V9etJfiDJ41trn+57PwO3muRvJtmsv/omdkmSJ1TVTyX5+jbEolv/Pp0dPy+3\nHU/yj3f7AgsNA7v9oKOq2sisFfnwbH/owvbc8iFJPtbhFgdpjuv2T5P8yx0PXZHZp1cdTHJrN7sb\npnk+VGv7jsAtSf5Xkud1ua8xaq19efu/yScleWty923vJyV5TZ97G7rtIPD0JE9srX287/2MwNsz\ne/fYTjdn9oPt5YLAOb07s5+XOz08c/y8XPSdgV1prX2xqn4jyS9U1Scz+z/0M5mNCf5Tr5sbsNba\nJ3f+vqruzGxU8OHW2qf62dWwbd8ReEdmd1Z+Jsk3nfoHSWvtzBn5lL0yyc3boeDWzN6Ceb/MvlFz\nFlV1Q5K1JE9Lcud2uTdJtlprPqL9LLY/xO60TsX297HPtdbO/Jcvf+VVSd5dVS9O8ubM3s76/Mze\nMr0rgwwD2346yZczO2vgvknem+T7W2tbve5qfCTp8/v7mZVvHprZW+WSWYBqmd2eJElr7c3bb417\nWWbjgQ8keWpr7TP97mzQrsns79E7znj8UGbf19gd38MuoLX2vqr64SQvz+ytmB9Jcl1r7T/s9jUG\nec4AALA4Q31rIQCwIMIAAEycMAAAEycMAMDECQMAMHHCAABMnDAAABMnDADAxAkDADBxwgAATJww\nAAAT9/8BmLaei2U6ZjgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xe85f66d470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Re Lu 함수 그래프\n",
    "x = np.arange(-5, 5, 0.2)\n",
    "y = relu(x)\n",
    "plt.plot(x,y)\n",
    "plt.ylim(-1,5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "3.3 다차원 배열의 계산\n",
    "\n",
    "np.array를 잘 이용하면 신경망을 효율적으로 구현 가능.\n",
    "\n",
    "3.3.1 다차원 배열\n",
    "\n",
    "1차원 배열(벡터) 2차원 배열(행렬) 3차원 배열(큐브를 생각) ... N차원 배열도 생각 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "A = np.array([1,2,3,4])\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ndim(A) # 배열 A의 차원 (여기서는 벡터의 차원이 아니라 배열이 몇개인지 묻는 것)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape #배열 속 벡터의 차원을 말하는 듯."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 2차원 배열을 생각해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n"
     ]
    }
   ],
   "source": [
    "B = np.array([[1,2],[3,4],[5,6]]) #파이썬에서 행렬은 열부터 채워짐\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ndim(B) #B가 행의 요소 1개 열의 요소 1개 씩 해서 2개가 있으므로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.shape #첫번째 []안에 몇개의 3개의 원소, 각 [] 안에 2개의 원소가 있으므로"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3.2 행렬의 내적\n",
    "\n",
    "그림 3-11: 2x2 행렬 곱 표현.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19, 22],\n",
       "       [43, 50]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#행렬의 내적 구현\n",
    "A = np.array([[1,2],[3,4]])\n",
    "B = np.array([[5,6],[7,8]])\n",
    "np.dot(A,B) #두 행렬의 곱, 여기서는 행렬의 곱을 행렬의 내적이라고 표현한 듯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "행렬을 곱할 때 $\\mathbf{R}^{m \\times n} \\times \\mathbf{R}^{n \\times r} \\rightarrow \\mathbf{R}^{m \\times r}$ 의 원리를 생각해보면\n",
    "\n",
    "행렬을 곱할 때 사이즈에 주의해야 한다. 그렇지 않으면 오류가 남. (그림 3-12)\n",
    "\n",
    "3.3.3 신경망의 내적\n",
    "\n",
    "그림 3-14 의 신경망을 구현해보자.\n",
    "\n",
    "$\\mathbf{R}^{2}$의 데이터를 넣어서 $\\mathbf{R}^{3}$의 데이터가 나와야 하므로 가중치에 해당하는 행렬이 $\\mathbf{R}^{3 \\times 2}$이 되야함을 알 수있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5 11 17]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([1,2]) # (1,2)^T 형태의 데이터\n",
    "W = np.array([[1,2],[3,4],[5,6]])\n",
    "Y = np.dot(W,X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4 3층 신경망 구현\n",
    "\n",
    "지금까지 입력층(0층) 히든(1층) 결과(2층) 해서 총 2층 신경망을 했다.\n",
    "\n",
    "이번엔 히든을 2개 넣어서 3층 신경망을 구현해보자 (그림 3-15)\n",
    "\n",
    "3.4.1 표기법 설명\n",
    "\n",
    "신경망의 계산을 행렬로 처리할려고 한다.\n",
    "\n",
    "${w}_{ij}^{(k)}$ $:~~$j번째 노드에서 i번째로 가는 k층에서의 가중치\n",
    "\n",
    "3.4.2 각 층의 신호 전달 구현\n",
    "\n",
    "그림 3-17 : 입력층에서 1층으로 감 ${w}_{1j}^{(1)}$ 에 해당함\n",
    "\n",
    "그림에 해당하는 식을 나타내면 [식 3.8] $~~{a}_{1}^{(1)} = {w}_{11}^{(1)}{x}_{1}+{w}_{12}^{(1)}{x}_{2}+{b}_{1}^{(1)}$\n",
    "\n",
    "이걸 행렬로 나타내면, ${A}^{(1)}=\\mathbf{W}^{(1)}\\mathbf{X}+\\mathbf{B}^{(1)}$ 으로 나타낼 수 있다\n",
    "\n",
    "where $\\mathbf{A}^{(1)}=\\begin{pmatrix} {a}_{1}^{(1)} \\\\ {a}_{2}^{(1)} \\\\ {a}_{3}^{(1)} \\end{pmatrix}\n",
    " ~~~ \\mathbf{X}=\\begin{pmatrix} {x}_{1} \\\\ {x}_{2}\\end{pmatrix}\n",
    " ~~~ \\mathbf{B}^{(1)}=\\begin{pmatrix} {b}_{1}^{(1)} \\\\ {b}_{2}^{(1)} \\\\ {b}_{3}^{(1)} \\end{pmatrix}\n",
    " ~~~ \\mathbf{W}^{(1)}=\\begin{pmatrix} {w}_{11}^{(1)} & {w}_{12}^{(1)} \\\\ {w}_{21}^{(1)} & {w}_{22}^{(1)} \\\\ {w}_{31}^{(1)} & {w}_{32}^{(1)} \\end{pmatrix}$\n",
    "\n",
    "(책이랑은 Notation이 좀 다름. 수학에서 익숙한 기호로 바꿈)\n",
    "\n",
    "이 상황을 구현해보자\n",
    "\n",
    "\n",
    " $\\mathbf{A}^{(1)}=\\begin{pmatrix} {a}_{1}^{(1)} \\\\ {a}_{2}^{(1)} \\\\ {a}_{3}^{(1)} \\end{pmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.3  0.7  1.1]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([1.0, 0.5])\n",
    "W1 = np.array([[0.1, 0.2],[0.3, 0.4],[0.5, 0.6]])\n",
    "B1 = np.array([0.1, 0.2, 0.3])\n",
    "\n",
    "A1 = np.dot(W1,X)+B1\n",
    "print(A1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 코드 과정을 거쳐 그림 3-18 처럼 각 노드가 활성화 함수로 인해 활성화 될지 안될지가 결정이 된다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.57444252  0.66818777  0.75026011]\n"
     ]
    }
   ],
   "source": [
    "Z1 = sigmoid(A1)\n",
    "\n",
    "print(Z1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 1층에서 2층으로 가는 신경망을 구현해보자.\n",
    "\n",
    "그림 3-19를 식으로 나타내면,\n",
    "\n",
    "$\\mathbf{A}^{(2)}=\\mathbf{W}^{(2)}\\mathbf{Z}_{1}+\\mathbf{B}^{(2)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A2는 [ 0.51615984  1.21402696]\n",
      "Z2는 [ 0.62624937  0.7710107 ]\n"
     ]
    }
   ],
   "source": [
    "W2 = np.array([[0.1, 0.2, 0.3],[0.4, 0.5, 0.6]])\n",
    "B2 = np.array([0.1, 0.2])\n",
    "\n",
    "A2 = np.dot(W2,Z1)+B2\n",
    "Z2 = sigmoid(A2)\n",
    "\n",
    "print('A2는 {}\\nZ2는 {}'.format(A2,Z2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 2층에서 3층으로 가는 신경망 구현\n",
    "그림 3-20을 식으로 나타내면,\n",
    "\n",
    "$\\mathbf{A}^{(3)}=\\mathbf{W}^{(3)}\\mathbf{Z}_{2}+\\mathbf{B}^{(3)}$\n",
    "\n",
    "단, 마지막 층이 이제 출력층이니까 활성화 함수를 identity를 사용하면,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.31682708  0.69627909]\n"
     ]
    }
   ],
   "source": [
    "def identity_function(x):\n",
    "    return x\n",
    "\n",
    "W3 = np.array([[0.1, 0.2],[0.3, 0.4]])\n",
    "B3 = np.array([0.1, 0.2])\n",
    "\n",
    "A3 = np.dot(W3,Z2)+B3\n",
    "Y = identity_function(A3)\n",
    "\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "출력층의 활성화 함수는 풀고자 하는 문제에 맞게 설정하면 된다. \n",
    "\n",
    "어떤 문제에 어떤 활성화 함수를 쓸건지는 나중에 다시 설명.\n",
    "\n",
    "3.4.3 구현 정리\n",
    "\n",
    "앞선 3층의 신경망을 정리해보면"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.31682708  0.69627909]\n"
     ]
    }
   ],
   "source": [
    "def init_network():\n",
    "    network={}\n",
    "    network['W1']= np.array([[0.1, 0.2],[0.3, 0.4],[0.5, 0.6]])\n",
    "    network['W2']= np.array([[0.1, 0.2, 0.3],[0.4, 0.5, 0.6]])\n",
    "    network['W3']= np.array([[0.1, 0.2],[0.3, 0.4]]) \n",
    "    network['b1']= np.array([0.1, 0.2, 0.3])\n",
    "    network['b2']= np.array([0.1, 0.2]) \n",
    "    network['b3']= np.array([0.1, 0.2]) \n",
    "    \n",
    "    return network\n",
    "\n",
    "def forward(network, x):\n",
    "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
    "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
    "    \n",
    "    a1 = np.dot(W1,x)+b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(W2,z1)+b2\n",
    "    z2 = sigmoid(a2)\n",
    "    a3 = np.dot(W3,z2)+b3\n",
    "    y = identity_function(a3)\n",
    "    \n",
    "    return y\n",
    "\n",
    "network = init_network()\n",
    "x = np.array([1.0, 0.5])\n",
    "y = forward(network, x)\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 코드에서 가중치만 적절히 조절하면, 아주 간단한 3층 신경망 모델이 완성되었다.\n",
    "\n",
    "신경망 모델의 이름을 forward (앞으로)으로 한것은 \n",
    "\n",
    "신경망의 진행방향이 입력층(왼쪽)을 기준으로 출력층(오른쪽)으로 가는 방향을 forward로 하기 위해서이다.\n",
    "\n",
    "뒤에 backpropagation(?)을 염두에 두고 한 말 같음.\n",
    "\n",
    "3.5 출력층 설계하기\n",
    "\n",
    "신경망은 회귀, 분류 둘 다 사용 가능한데,\n",
    "\n",
    "각각 출력층에서 활성함수를 다른걸로 사용한다.\n",
    "\n",
    "회귀는 주로 항등함수를 사용하고 분류는 softmax 함수를 사용함.\n",
    "\n",
    "3.5.1 항등함수와 softmax 함수 구현\n",
    "\n",
    "항등 함수는 $\\mathbf{I(x)=x}$ 이고,\n",
    "\n",
    "softmax 함수는 식 3.10 $\\mathbf{y}_{k} = \\frac{exp(\\mathbf{a}_{k})}{\\sum exp(\\mathbf{a}_{i})}$ 으로 나타난다.\n",
    "\n",
    "그림 3-22 softmax 함수 설명\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01821127  0.24519181  0.73659691]\n"
     ]
    }
   ],
   "source": [
    "#softmax 함수 구현\n",
    "\n",
    "def softmax(a):\n",
    "    exp_a = np.exp(a)\n",
    "    sum_exp_a = np.sum(exp_a) #벡터 원소의 합\n",
    "    y = exp_a / sum_exp_a #원소 별로 스칼라가 들어감.\n",
    "    return y\n",
    "\n",
    "a = np.array([0.3, 2.9, 4])\n",
    "\n",
    "print(softmax(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.5.2 소프트맥스 함수 구현 시 주의점\n",
    "\n",
    "exp함수는 지수함수라 monotone이 아니라 엄청 크게 증가한다. 그래서 컴퓨터가 연산할 수 있는 범위를 초과할 수도 있다.overflow(오버플로)라고 함.\n",
    "\n",
    "그래서 원래의 값에는 영향을 주진 않지만, 계산의 안정성을 위하여 식을 약간 변형 한다. 간단한 수학이 쓰인다 식[3.11]\n",
    "\n",
    "식 3.11에 해당하는 내용을 구현해보자.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'softmax' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-c06c66c3b8bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1010\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m999\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#아마 계산 에러가 나올거다\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'softmax' is not defined"
     ]
    }
   ],
   "source": [
    "a = np.array([1010, 1000, 999])\n",
    "print(softmax(a)) #아마 계산 에러가 나올거다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  9.99937902e-01   4.53971105e-05   1.67006637e-05]\n"
     ]
    }
   ],
   "source": [
    "c = np.max(a)\n",
    "print(softmax(a-c)) #여기서는 c값을 빼줌. 값은 달라도 비율은 같을 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "softmax의 값이 얼마인지도 중요하지만 분류문제에서는 softmax의 값이 큰 값으로 분류를 하면 되므로 크기비교만 있으면 된다.\n",
    "\n",
    "이걸 감안해서 softmax함수를 조금 보정 해보자\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#overflow 수정된 softmax 함수\n",
    "def softmax(a):\n",
    "    c = np.max(a)\n",
    "    exp_a = np.exp(a-c)\n",
    "    sum_exp_a = np.sum(exp_a) #벡터 원소의 합\n",
    "    y = exp_a / sum_exp_a #원소 별로 스칼라가 들어감.\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.5.3 소프트맥스 함수의 특징\n",
    "\n",
    "출력값의 성분이 모두 0에서 1사이의 값이다.\n",
    "\n",
    "그리고 출력값의 성분을 모두 더하면 1이다.\n",
    "\n",
    "이는 확률의 성질과 비슷하다. 그렇다. 소프트맥스 함수는 확률함수로 볼 수도있다.\n",
    "\n",
    "그래서 분류문제에서 이를 응용할 수 있다.\n",
    "\n",
    "예를 들어 출력값이 y=(0.2, 0.3, 0.5) 로 나왔다면 입력데이터의 클래스가 1일 확률이 20%, 2일 확률이 30%, 3일 확률이 50%라고 해석할 수 있다.\n",
    "\n",
    "그런데 소프트맥스 함수는 monotone increasing 함수이므로, 정의역의 값이 크면 함수값도 크다.\n",
    "\n",
    "그래서 굳이 마지막 출력층에서의 소프트맥스 함수 계산과정은 사실상 생략이 가능하다.\n",
    "\n",
    "하지만 나중에 모델을 학습시키는 과정에서는 출력과정에서 소프트맥스 함수 계산과정이 필요함. (4장에서 다시 언급)\n",
    "\n",
    "3.5.4 출력층의 뉴런 수 정하기\n",
    "\n",
    "분류 문제의 경우에는 클래스의 갯수 = 출력층의 노드 수 [그림 3-22]\n",
    "\n",
    "3.6 손글씨 숫자 인식\n",
    "\n",
    "학습단계는 다시 하고 이미 계산된 최적의 모수를 가지고 추론만 해보자. \n",
    "\n",
    "이런 과정을 순전파 (forward propagation)이라고 한다.\n",
    "\n",
    "3.6.1 MNIST 데이터 셋\n",
    "\n",
    "MNIST(Mixed National Institute of Standards and Technology database)는 손글씨로 쓰여진 숫자 데이터 셋(트레이닝 셋 6만장, 테스트셋 10만장)을 의미한다.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting train-images-idx3-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Converting train-labels-idx1-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Converting t10k-images-idx3-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Converting t10k-labels-idx1-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Creating pickle file ...\n",
      "Done!\n",
      "(60000, 784)\n",
      "(60000,)\n",
      "(10000, 784)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "from dataset.mnist import load_mnist #data.mnist라는 코드 파일 안에 load_mnist라는 함수코드를 불러오라는 뜻\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=True, normalize=False)\n",
    "\n",
    "#각 데이터의 형상 출력\n",
    "print(x_train.shape) # (60000, 784)\n",
    "print(t_train.shape) # (60000,)\n",
    "print(x_test.shape) # (10000, 784)\n",
    "print(t_test.shape) # (10000, )\n",
    "#위의 이녀석들의 의미는...??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load_mnist 함수 특징 설명\n",
    "\n",
    "인수: normalize, flatten, one_hot_label 3가지가 있다. 모두 인자를 bool값(True or False)으로 입력받는다.\n",
    "\n",
    "normalize : 입력 이미지의 픽셀 값을 0.0~1.0사이의 값으로 정규화 (False 시 0~255로 나옴)\n",
    "\n",
    "flattern : 이미지를 1차원 배열로 만듬 (False 시 $1 \\times 28 \\times 28$의 3차원 배열로 나옴)\n",
    "\n",
    "one_hot_label : 다시.... 원 핫 인코딩??\n",
    "\n",
    "그러면 MNIST 이미지를 화면으로 불러보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그림1![title](/notebooks/da.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "(784,)\n",
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "from PIL import Image #이미지를 불러올때 사용되는 모듈\n",
    "\n",
    "\n",
    "def img_show(img):\n",
    "    pil_img = Image.fromarray(np.uint8(img))\n",
    "    pil_img.show()\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=True, normalize=False)\n",
    "\n",
    "img = x_train[0] #x_train이란 배열에 첫번째 있는 이미지인듯\n",
    "label = t_train[0] #그 이미지의 이름??\n",
    "print(label)  # 5\n",
    "\n",
    "print(img.shape)  # (784,) 784개의 원소로 이루어진 1차원 배열\n",
    "img = img.reshape(28, 28)  # 형상을 원래 이미지의 크기로 변형 -> 1x28x28은 파이썬이 읽지 못하더라. 28x28은 읽는 듯.\n",
    "print(img.shape)  # (28, 28)\n",
    "\n",
    "img_show(img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "살펴 보아야 할 것이, img를 불러 들일 때 784개의 원소로 이루어진 배열로 불러오지만,\n",
    "\n",
    "이미지를 불러올 때는 $28 \\times 28$로 불러와야 하기 때문에 image.reshape를 해준다.\n",
    "\n",
    "그리고 지금 이미지를 PIL이란 모듈로 불러오기 때문에, numpy로 저장된 데이터를 PIL용으로 변환 해주어야 하며 그 변환을 Image.fromarray가 한다.\n",
    "\n",
    "3.6.2 신경망의 추론 처리\n",
    "\n",
    "이제 이 MNIST 데이터를 신경망으로 부터 추론을 해보자.\n",
    "\n",
    "각 $28 \\times 28$의 이미지 데이터를 784개의 원소로 이루어진 1개의 배열로 입력데이터로 받아서\n",
    "\n",
    "0~10 까지 숫자를 판별하는 10개의 출력층을 가진 신경망을 구성할 것이다.\n",
    "\n",
    "그리고 은닉층은 2개로 첫번째는 50개, 두번째는 100개로 뉴런을 배치. (이때 50, 100은 임의로 정함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9352\n"
     ]
    }
   ],
   "source": [
    "# Neural Network 구현\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import pickle\n",
    "from dataset.mnist import load_mnist\n",
    "from common.functions import sigmoid, softmax\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    (x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, flatten=True, one_hot_label=False)\n",
    "    return x_test, t_test\n",
    "\n",
    "\n",
    "def init_network():\n",
    "    with open(\"ch03/sample_weight.pkl\", 'rb') as f:\n",
    "        network = pickle.load(f)\n",
    "    return network\n",
    "\n",
    "    \n",
    "\n",
    "def predict(network, x):\n",
    "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
    "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
    "\n",
    "    a1 = np.dot(x, W1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1, W2) + b2\n",
    "    z2 = sigmoid(a2)\n",
    "    a3 = np.dot(z2, W3) + b3\n",
    "    y = softmax(a3)\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "x, t = get_data()\n",
    "\n",
    "network = init_network()\n",
    "accuracy_cnt = 0\n",
    "for i in range(len(x)):\n",
    "    y = predict(network, x[i])\n",
    "    p= np.argmax(y) # 확률이 가장 높은 원소의 인덱스를 얻는다.\n",
    "    if p == t[i]:\n",
    "        accuracy_cnt += 1\n",
    "\n",
    "print(\"Accuracy:\" + str(float(accuracy_cnt) / len(x)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "코드를 살펴보자.\n",
    "\n",
    "우선 get_data로 부터 데이터를 우리가 원하는 방식으로 셋팅한다(784개의 원소로 이루어진 1차원 배열, 각 원소가 0~1사이 값)\n",
    "\n",
    "그리고 predict 함수로 분류를 한다. 이 때 분류 원리는 출력값이 배열로 나오는데 배열 중 가장 숫자가 큰 즉, 가장 확률이 큰 값으로 분류를 함.\n",
    "\n",
    "그 배열중 가장 큰 값을 뽑아내는 함수가 np.argmax()이다.\n",
    "\n",
    "그리고 총 데이터의 갯수중 정답이 맞은 횟수를 통해 accuracy를 출력한다.\n",
    "\n",
    "93.52%의 정확도가 나오는데 뒤에 학습을 시켜서 99%까지 향상시킬 것이다.\n",
    "\n",
    "앞서 데이터 배열의 각 원소 값이 0~1사이의 값으로 정규화 시켰는데(원래 0~255값에서) 이렇게 원래 데이터를 특정 변환시키는 과정을 전처리라고 한다.\n",
    "\n",
    "3.6.3 배치 처리\n",
    "\n",
    "앞서 $A = WX + B $ 에서의 각 행렬의 사이즈를 생각해보자.\n",
    "\n",
    "입력 데이터가 784개의 성분을 가진 데이터이니까\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape 는 (10000, 784)\n",
      "x[0].shape 는 (784,)\n",
      "W1.shape 는 (784, 50)\n",
      "W2.shape 는 (50, 100)\n",
      "W3.shape는 (100, 10)\n"
     ]
    }
   ],
   "source": [
    "x, _ = get_data()\n",
    "network = init_network()\n",
    "\n",
    "W1,W2,W3 = network['W1'], network['W2'], network['W3']\n",
    "\n",
    "print(\"x.shape 는 {}\\nx[0].shape 는 {}\\nW1.shape 는 {}\\nW2.shape 는 {}\\nW3.shape는 {}\". format(x.shape, x[0].shape, W1.shape, W2.shape, W3.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "그림 3-26 처럼 행렬 곱이 well-defined 된다.\n",
    "\n",
    "그러면 같은 원리로 X를 $ 784 \\times 1 $ 행렬이 아니라\n",
    "\n",
    "$ 784 \\times 100 $ 행렬을 입력해도 괜찮지 않을까?  (1열이 첫번째 데이터 .... 100열은 100번째 데이터 생각)\n",
    "\n",
    "그러면 이론적으로는 그림 3-27이 된다 (책에서의 행렬표시에 모두 transpose를 취하면 수학적 표현과 맞다)\n",
    "\n",
    "이처럼 입력데이터를 몇개의 단위로 묶는 것을 배치라고 한다.\n",
    "\n",
    "사실 컴퓨터는 하나를 계산하는것 보다 배치로 계산하는게 더 빠르게 설계되어있다고 한다.\n",
    "\n",
    "배치를 고려해서 다시 구현해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9352\n"
     ]
    }
   ],
   "source": [
    "x, t = get_data()\n",
    "network = init_network()\n",
    "\n",
    "batch_size = 100 # 배치의 크기는 100\n",
    "accuracy_cnt = 0\n",
    "\n",
    "for i in range(0, len(x), batch_size): #0에서 len(x) 까지 batch_size만큼 끊어라\n",
    "    x_batch = x[i:i+batch_size] # 784 x 100 행렬\n",
    "    y_batch = predict(network, x_batch) #결과는 10 x 100 행렬이 나온다 여기선 100 x 10 행렬\n",
    "    p = np.argmax(y_batch, axis=1) # 첫번째 행 중에 가장 큰 숫자\n",
    "    accuracy_cnt += np.sum(p == t[i:i+batch_size])\n",
    "    \n",
    "print(\"Accuracy:\" + str(float(accuracy_cnt) / len(x)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서 잠깐 반복문에 range를 살펴보고 가자. \n",
    "\n",
    "위에서 설명했듯이 range(start, end, step)으로 이루어져있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 3, 6, 9]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(0,10,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그리고 배열에서의 argmax는 어떻게 되는지 생각해보면, axis=1이라는 것은 $100 \\times 10$을 구성하는 첫번째 차원에서 가장 큰 index를 출력한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 1 0]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[0.1, 0.8, 0.1],[0.3, 0.1, 0.6],[0.2, 0.5, 0.3],[0.8, 0.1, 0.1]]) # 4x3 행렬\n",
    "y = np.argmax(x, axis=1) #1행 중가장 큰 수를 나타내는 index!\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실제 답과 비교하기 위해서 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True False  True]\n"
     ]
    }
   ],
   "source": [
    "t = np.array([1,2,0,0])\n",
    "print(y==t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y==t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "총 3개 맞았다.\n",
    "\n",
    "3.7 정리\n",
    "\n",
    "입력층을 출발로 출력층으로 가는 알고리즘의 순서는 퍼셉트론과 같다.\n",
    "\n",
    "하지만 퍼셉트론은 활성화 함수를 step function으로 사용한 반면에,\n",
    "\n",
    "신경망은 활성화 함수를 부드러운 시그모이드 함수를 사용했다.\n",
    "\n",
    "왜 이렇게 나뉘는지 다음장에서 살펴보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "3장 총 정리\n",
    "\n",
    "신경망에서는 활성화 함수로 시그모이드 함수와 ReLu 함수를 주로 이용.\n",
    "\n",
    "Numpy의 배열을 잘 이용하면 좀 더 효율적으로 신경망 구현 가능.\n",
    "\n",
    "기계학습은 크게 regression(회귀)와 classification(분류)로 나눌 수 있음.\n",
    "\n",
    "출력층의 활성화 함수로 회귀에서는 주로 항등함수, 분류에서는 주로 소프트맥스 함수 사용.\n",
    "\n",
    "분류에서는 출력층의 뉴런(노드)의 수를 클래스의 수와 같게 설정.\n",
    "\n",
    "입력데이터를 묶은 것을 배치라고 하며, 배치단위로 데이터를 처리하면 좀 더 효율적임.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
